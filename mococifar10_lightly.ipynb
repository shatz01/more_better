{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47eb48b9",
   "metadata": {},
   "source": [
    "# Lightly is great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55155651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shatz/miniconda3/envs/morebetter2/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n",
      "/home/shatz/miniconda3/envs/morebetter2/lib/python3.8/site-packages/lightly/api/version_checking.py:57: Warning: You are using lightly version 1.1.15. There is a newer version of the package available. For compatability reasons, please upgrade your current version: pip install lightly==1.1.16\n",
      "  warnings.warn(Warning(warning))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import lightly\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import loggers as pl_loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2161f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset structure should be like this:\n",
    "# cifar10/train/\n",
    "#  L airplane/\n",
    "#    L 10008_airplane.png\n",
    "#    L ...\n",
    "#  L automobile/\n",
    "#  L bird/\n",
    "#  L cat/\n",
    "#  L deer/\n",
    "#  L dog/\n",
    "#  L frog/\n",
    "#  L horse/\n",
    "#  L ship/\n",
    "#  L truck/\n",
    "path_to_train = './data/cifar10_lightly/train/'\n",
    "path_to_test = './data/cifar10_lightly/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca04edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoCo v2 uses SimCLR augmentations, additionally, disable blur\n",
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=32,\n",
    "    gaussian_blur=0.,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8545a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations typically used to train on cifar-10\n",
    "train_classifier_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "        std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "# No additional augmentations for the test set\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32, 32)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "        std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "# We use the moco augmentations for training moco\n",
    "dataset_train_moco = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_train\n",
    ")\n",
    "\n",
    "# Since we also train a linear classifier on the pre-trained moco model we\n",
    "# reuse the test augmentations here (MoCo augmentations are very strong and\n",
    "# usually reduce accuracy of models which are not used for contrastive learning.\n",
    "# Our linear layer will be trained using cross entropy loss and labels provided\n",
    "# by the dataset. Therefore we chose light augmentations.)\n",
    "dataset_train_classifier = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_train,\n",
    "    transform=train_classifier_transforms\n",
    ")\n",
    "\n",
    "dataset_test = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_test,\n",
    "    transform=test_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721404d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "num_workers = 6\n",
    "batch_size = 512\n",
    "memory_bank_size = 4096\n",
    "seed = 1\n",
    "max_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8ab836",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train_moco = torch.utils.data.DataLoader(\n",
    "    dataset_train_moco,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "dataloader_train_classifier = torch.utils.data.DataLoader(\n",
    "    dataset_train_classifier,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97281123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MocoModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = lightly.models.ResNetGenerator('resnet-18', 1, num_splits=8)\n",
    "        backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1],\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "\n",
    "        # create a moco based on ResNet\n",
    "        self.resnet_moco = \\\n",
    "            lightly.models.MoCo(backbone, num_ftrs=512, m=0.99, batch_shuffle=True)\n",
    "\n",
    "        # create our loss with the optional memory bank\n",
    "        self.criterion = lightly.loss.NTXentLoss(\n",
    "            temperature=0.1,\n",
    "            memory_bank_size=memory_bank_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.resnet_moco(x)\n",
    "\n",
    "    # We provide a helper method to log weights in tensorboard\n",
    "    # which is useful for debugging.\n",
    "    def custom_histogram_weights(self):\n",
    "        for name, params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(\n",
    "                name, params, self.current_epoch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        y0, y1 = self.resnet_moco(x0, x1)\n",
    "        loss = self.criterion(y0, y1)\n",
    "        self.log('train_loss_ssl', loss)\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        self.custom_histogram_weights()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.resnet_moco.parameters(), lr=6e-2,\n",
    "                                momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b6ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shatz/miniconda3/envs/morebetter2/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: UserWarning: Checkpoint directory ./saved_models/resnet_moco exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    }
   ],
   "source": [
    "# you can also define a checkpoint callback to save best model like keras.\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='./saved_models/resnet_moco',\n",
    "    filename='{epoch}-{train_loss_ssl:.2f}',\n",
    "    save_top_k=5,\n",
    "    verbose=True,\n",
    "    monitor='train_loss_ssl',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94914ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8d2a95191685420d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8d2a95191685420d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f26a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | resnet_moco | MoCo       | 23.0 M\n",
      "1 | criterion   | NTXentLoss | 0     \n",
      "-------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "11.5 M    Non-trainable params\n",
      "23.0 M    Total params\n",
      "91.977    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af86640e84124a7f9c21bdc52973e30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 96: train_loss_ssl reached 6.98624 (best 6.98624), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=0-train_loss_ssl=6.99.ckpt\" as top 5\n",
      "Epoch 1, global step 193: train_loss_ssl reached 7.15018 (best 6.98624), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=1-train_loss_ssl=7.15.ckpt\" as top 5\n",
      "Epoch 2, global step 290: train_loss_ssl reached 6.95802 (best 6.95802), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=2-train_loss_ssl=6.96.ckpt\" as top 5\n",
      "Epoch 3, global step 387: train_loss_ssl reached 6.76561 (best 6.76561), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=3-train_loss_ssl=6.77.ckpt\" as top 5\n",
      "Epoch 4, global step 484: train_loss_ssl reached 6.57230 (best 6.57230), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=4-train_loss_ssl=6.57.ckpt\" as top 5\n",
      "Epoch 5, global step 581: train_loss_ssl reached 6.30364 (best 6.30364), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=5-train_loss_ssl=6.30.ckpt\" as top 5\n",
      "Epoch 6, global step 678: train_loss_ssl reached 6.12896 (best 6.12896), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=6-train_loss_ssl=6.13.ckpt\" as top 5\n",
      "Epoch 7, global step 775: train_loss_ssl reached 6.03397 (best 6.03397), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=7-train_loss_ssl=6.03.ckpt\" as top 5\n",
      "Epoch 8, global step 872: train_loss_ssl reached 5.76985 (best 5.76985), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=8-train_loss_ssl=5.77.ckpt\" as top 5\n",
      "Epoch 9, global step 969: train_loss_ssl reached 5.55123 (best 5.55123), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=9-train_loss_ssl=5.55.ckpt\" as top 5\n",
      "Epoch 10, global step 1066: train_loss_ssl reached 5.49140 (best 5.49140), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=10-train_loss_ssl=5.49.ckpt\" as top 5\n",
      "Epoch 11, global step 1163: train_loss_ssl reached 5.38152 (best 5.38152), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=11-train_loss_ssl=5.38.ckpt\" as top 5\n",
      "Epoch 12, global step 1260: train_loss_ssl reached 5.20663 (best 5.20663), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=12-train_loss_ssl=5.21.ckpt\" as top 5\n",
      "Epoch 13, global step 1357: train_loss_ssl reached 5.29747 (best 5.20663), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=13-train_loss_ssl=5.30.ckpt\" as top 5\n",
      "Epoch 14, global step 1454: train_loss_ssl reached 5.14789 (best 5.14789), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=14-train_loss_ssl=5.15.ckpt\" as top 5\n",
      "Epoch 15, global step 1551: train_loss_ssl reached 4.88815 (best 4.88815), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=15-train_loss_ssl=4.89.ckpt\" as top 5\n",
      "Epoch 16, global step 1648: train_loss_ssl reached 5.04753 (best 4.88815), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=16-train_loss_ssl=5.05.ckpt\" as top 5\n",
      "Epoch 17, global step 1745: train_loss_ssl reached 4.65472 (best 4.65472), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=17-train_loss_ssl=4.65.ckpt\" as top 5\n",
      "Epoch 18, global step 1842: train_loss_ssl reached 4.75634 (best 4.65472), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=18-train_loss_ssl=4.76.ckpt\" as top 5\n",
      "Epoch 19, global step 1939: train_loss_ssl reached 4.71450 (best 4.65472), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=19-train_loss_ssl=4.71.ckpt\" as top 5\n",
      "Epoch 20, global step 2036: train_loss_ssl reached 4.55953 (best 4.55953), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=20-train_loss_ssl=4.56.ckpt\" as top 5\n",
      "Epoch 21, global step 2133: train_loss_ssl reached 4.50992 (best 4.50992), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=21-train_loss_ssl=4.51.ckpt\" as top 5\n",
      "Epoch 22, global step 2230: train_loss_ssl reached 4.50579 (best 4.50579), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=22-train_loss_ssl=4.51.ckpt\" as top 5\n",
      "Epoch 23, global step 2327: train_loss_ssl reached 4.40833 (best 4.40833), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=23-train_loss_ssl=4.41.ckpt\" as top 5\n",
      "Epoch 24, global step 2424: train_loss_ssl reached 4.21572 (best 4.21572), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=24-train_loss_ssl=4.22.ckpt\" as top 5\n",
      "Epoch 25, global step 2521: train_loss_ssl reached 4.10624 (best 4.10624), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=25-train_loss_ssl=4.11.ckpt\" as top 5\n",
      "Epoch 26, global step 2618: train_loss_ssl reached 4.13619 (best 4.10624), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=26-train_loss_ssl=4.14.ckpt\" as top 5\n",
      "Epoch 27, global step 2715: train_loss_ssl reached 4.14287 (best 4.10624), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=27-train_loss_ssl=4.14.ckpt\" as top 5\n",
      "Epoch 28, global step 2812: train_loss_ssl reached 4.08945 (best 4.08945), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=28-train_loss_ssl=4.09.ckpt\" as top 5\n",
      "Epoch 29, global step 2909: train_loss_ssl reached 4.03504 (best 4.03504), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=29-train_loss_ssl=4.04.ckpt\" as top 5\n",
      "Epoch 30, global step 3006: train_loss_ssl reached 4.08182 (best 4.03504), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=30-train_loss_ssl=4.08.ckpt\" as top 5\n",
      "Epoch 31, global step 3103: train_loss_ssl reached 3.89466 (best 3.89466), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=31-train_loss_ssl=3.89.ckpt\" as top 5\n",
      "Epoch 32, global step 3200: train_loss_ssl reached 3.79539 (best 3.79539), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=32-train_loss_ssl=3.80.ckpt\" as top 5\n",
      "Epoch 33, global step 3297: train_loss_ssl reached 3.89543 (best 3.79539), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=33-train_loss_ssl=3.90.ckpt\" as top 5\n",
      "Epoch 34, global step 3394: train_loss_ssl reached 3.94477 (best 3.79539), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=34-train_loss_ssl=3.94.ckpt\" as top 5\n",
      "Epoch 35, global step 3491: train_loss_ssl reached 3.95363 (best 3.79539), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=35-train_loss_ssl=3.95.ckpt\" as top 5\n",
      "Epoch 36, global step 3588: train_loss_ssl reached 3.78779 (best 3.78779), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=36-train_loss_ssl=3.79.ckpt\" as top 5\n",
      "Epoch 37, global step 3685: train_loss_ssl reached 3.74663 (best 3.74663), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=37-train_loss_ssl=3.75.ckpt\" as top 5\n",
      "Epoch 38, global step 3782: train_loss_ssl reached 3.67714 (best 3.67714), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=38-train_loss_ssl=3.68.ckpt\" as top 5\n",
      "Epoch 39, global step 3879: train_loss_ssl reached 3.72257 (best 3.67714), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=39-train_loss_ssl=3.72.ckpt\" as top 5\n",
      "Epoch 40, global step 3976: train_loss_ssl reached 3.78675 (best 3.67714), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=40-train_loss_ssl=3.79.ckpt\" as top 5\n",
      "Epoch 41, global step 4073: train_loss_ssl reached 3.66578 (best 3.66578), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=41-train_loss_ssl=3.67.ckpt\" as top 5\n",
      "Epoch 42, global step 4170: train_loss_ssl reached 3.63581 (best 3.63581), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=42-train_loss_ssl=3.64.ckpt\" as top 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 4267: train_loss_ssl reached 3.47386 (best 3.47386), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=43-train_loss_ssl=3.47.ckpt\" as top 5\n",
      "Epoch 44, global step 4364: train_loss_ssl was not in top 5\n",
      "Epoch 45, global step 4461: train_loss_ssl reached 3.43905 (best 3.43905), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=45-train_loss_ssl=3.44.ckpt\" as top 5\n",
      "Epoch 46, global step 4558: train_loss_ssl reached 3.55804 (best 3.43905), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=46-train_loss_ssl=3.56.ckpt\" as top 5\n",
      "Epoch 47, global step 4655: train_loss_ssl reached 3.61927 (best 3.43905), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=47-train_loss_ssl=3.62.ckpt\" as top 5\n",
      "Epoch 48, global step 4752: train_loss_ssl reached 3.44943 (best 3.43905), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=48-train_loss_ssl=3.45.ckpt\" as top 5\n",
      "Epoch 49, global step 4849: train_loss_ssl reached 3.50882 (best 3.43905), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=49-train_loss_ssl=3.51.ckpt\" as top 5\n",
      "Epoch 50, global step 4946: train_loss_ssl reached 3.50768 (best 3.43905), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=50-train_loss_ssl=3.51.ckpt\" as top 5\n",
      "Epoch 51, global step 5043: train_loss_ssl was not in top 5\n",
      "Epoch 52, global step 5140: train_loss_ssl reached 3.40687 (best 3.40687), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=52-train_loss_ssl=3.41.ckpt\" as top 5\n",
      "Epoch 53, global step 5237: train_loss_ssl was not in top 5\n",
      "Epoch 54, global step 5334: train_loss_ssl reached 3.39646 (best 3.39646), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=54-train_loss_ssl=3.40.ckpt\" as top 5\n",
      "Epoch 55, global step 5431: train_loss_ssl was not in top 5\n",
      "Epoch 56, global step 5528: train_loss_ssl reached 3.40561 (best 3.39646), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=56-train_loss_ssl=3.41.ckpt\" as top 5\n",
      "Epoch 57, global step 5625: train_loss_ssl reached 3.36313 (best 3.36313), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=57-train_loss_ssl=3.36.ckpt\" as top 5\n",
      "Epoch 58, global step 5722: train_loss_ssl reached 3.16686 (best 3.16686), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=58-train_loss_ssl=3.17.ckpt\" as top 5\n",
      "Epoch 59, global step 5819: train_loss_ssl reached 3.29797 (best 3.16686), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=59-train_loss_ssl=3.30.ckpt\" as top 5\n",
      "Epoch 60, global step 5916: train_loss_ssl was not in top 5\n",
      "Epoch 61, global step 6013: train_loss_ssl reached 3.21741 (best 3.16686), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=61-train_loss_ssl=3.22.ckpt\" as top 5\n",
      "Epoch 62, global step 6110: train_loss_ssl reached 3.30442 (best 3.16686), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=62-train_loss_ssl=3.30.ckpt\" as top 5\n",
      "Epoch 63, global step 6207: train_loss_ssl reached 3.16374 (best 3.16374), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=63-train_loss_ssl=3.16.ckpt\" as top 5\n",
      "Epoch 64, global step 6304: train_loss_ssl reached 3.17678 (best 3.16374), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=64-train_loss_ssl=3.18.ckpt\" as top 5\n",
      "Epoch 65, global step 6401: train_loss_ssl reached 3.26062 (best 3.16374), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=65-train_loss_ssl=3.26.ckpt\" as top 5\n",
      "Epoch 66, global step 6498: train_loss_ssl was not in top 5\n",
      "Epoch 67, global step 6595: train_loss_ssl reached 3.20637 (best 3.16374), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=67-train_loss_ssl=3.21.ckpt\" as top 5\n",
      "Epoch 68, global step 6692: train_loss_ssl reached 3.13933 (best 3.13933), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=68-train_loss_ssl=3.14.ckpt\" as top 5\n",
      "Epoch 69, global step 6789: train_loss_ssl reached 3.09826 (best 3.09826), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=69-train_loss_ssl=3.10.ckpt\" as top 5\n",
      "Epoch 70, global step 6886: train_loss_ssl reached 3.15561 (best 3.09826), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=70-train_loss_ssl=3.16.ckpt\" as top 5\n",
      "Epoch 71, global step 6983: train_loss_ssl reached 3.09884 (best 3.09826), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=71-train_loss_ssl=3.10.ckpt\" as top 5\n",
      "Epoch 72, global step 7080: train_loss_ssl reached 3.15360 (best 3.09826), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=72-train_loss_ssl=3.15.ckpt\" as top 5\n",
      "Epoch 73, global step 7177: train_loss_ssl was not in top 5\n",
      "Epoch 74, global step 7274: train_loss_ssl reached 3.12496 (best 3.09826), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=74-train_loss_ssl=3.12.ckpt\" as top 5\n",
      "Epoch 75, global step 7371: train_loss_ssl reached 3.05978 (best 3.05978), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=75-train_loss_ssl=3.06.ckpt\" as top 5\n",
      "Epoch 76, global step 7468: train_loss_ssl was not in top 5\n",
      "Epoch 77, global step 7565: train_loss_ssl was not in top 5\n",
      "Epoch 78, global step 7662: train_loss_ssl reached 2.98723 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=78-train_loss_ssl=2.99.ckpt\" as top 5\n",
      "Epoch 79, global step 7759: train_loss_ssl reached 3.03723 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=79-train_loss_ssl=3.04.ckpt\" as top 5\n",
      "Epoch 80, global step 7856: train_loss_ssl reached 3.00574 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=80-train_loss_ssl=3.01.ckpt\" as top 5\n",
      "Epoch 81, global step 7953: train_loss_ssl reached 2.99099 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=81-train_loss_ssl=2.99.ckpt\" as top 5\n",
      "Epoch 82, global step 8050: train_loss_ssl was not in top 5\n",
      "Epoch 83, global step 8147: train_loss_ssl reached 3.01230 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=83-train_loss_ssl=3.01.ckpt\" as top 5\n",
      "Epoch 84, global step 8244: train_loss_ssl was not in top 5\n",
      "Epoch 85, global step 8341: train_loss_ssl reached 3.02628 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=85-train_loss_ssl=3.03.ckpt\" as top 5\n",
      "Epoch 86, global step 8438: train_loss_ssl reached 3.01303 (best 2.98723), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=86-train_loss_ssl=3.01.ckpt\" as top 5\n",
      "Epoch 87, global step 8535: train_loss_ssl reached 2.96447 (best 2.96447), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=87-train_loss_ssl=2.96.ckpt\" as top 5\n",
      "Epoch 88, global step 8632: train_loss_ssl reached 2.97357 (best 2.96447), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=88-train_loss_ssl=2.97.ckpt\" as top 5\n",
      "Epoch 89, global step 8729: train_loss_ssl reached 2.90150 (best 2.90150), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=89-train_loss_ssl=2.90.ckpt\" as top 5\n",
      "Epoch 90, global step 8826: train_loss_ssl reached 2.83099 (best 2.83099), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=90-train_loss_ssl=2.83.ckpt\" as top 5\n",
      "Epoch 91, global step 8923: train_loss_ssl was not in top 5\n",
      "Epoch 92, global step 9020: train_loss_ssl reached 2.87616 (best 2.83099), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=92-train_loss_ssl=2.88.ckpt\" as top 5\n",
      "Epoch 93, global step 9117: train_loss_ssl reached 2.86449 (best 2.83099), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=93-train_loss_ssl=2.86.ckpt\" as top 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94, global step 9214: train_loss_ssl was not in top 5\n",
      "Epoch 95, global step 9311: train_loss_ssl reached 2.83680 (best 2.83099), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=95-train_loss_ssl=2.84.ckpt\" as top 5\n",
      "Epoch 96, global step 9408: train_loss_ssl was not in top 5\n",
      "Epoch 97, global step 9505: train_loss_ssl reached 2.88812 (best 2.83099), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=97-train_loss_ssl=2.89.ckpt\" as top 5\n",
      "Epoch 98, global step 9602: train_loss_ssl reached 2.80977 (best 2.80977), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=98-train_loss_ssl=2.81.ckpt\" as top 5\n",
      "Epoch 99, global step 9699: train_loss_ssl was not in top 5\n",
      "Epoch 100, global step 9796: train_loss_ssl reached 2.76853 (best 2.76853), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=100-train_loss_ssl=2.77.ckpt\" as top 5\n",
      "Epoch 101, global step 9893: train_loss_ssl reached 2.74601 (best 2.74601), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=101-train_loss_ssl=2.75.ckpt\" as top 5\n",
      "Epoch 102, global step 9990: train_loss_ssl reached 2.73803 (best 2.73803), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=102-train_loss_ssl=2.74.ckpt\" as top 5\n",
      "Epoch 103, global step 10087: train_loss_ssl was not in top 5\n",
      "Epoch 104, global step 10184: train_loss_ssl was not in top 5\n",
      "Epoch 105, global step 10281: train_loss_ssl reached 2.76324 (best 2.73803), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=105-train_loss_ssl=2.76.ckpt\" as top 5\n",
      "Epoch 106, global step 10378: train_loss_ssl was not in top 5\n",
      "Epoch 107, global step 10475: train_loss_ssl was not in top 5\n",
      "Epoch 108, global step 10572: train_loss_ssl reached 2.76406 (best 2.73803), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=108-train_loss_ssl=2.76.ckpt\" as top 5\n",
      "Epoch 109, global step 10669: train_loss_ssl reached 2.75741 (best 2.73803), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=109-train_loss_ssl=2.76.ckpt\" as top 5\n",
      "Epoch 110, global step 10766: train_loss_ssl was not in top 5\n",
      "Epoch 111, global step 10863: train_loss_ssl reached 2.62032 (best 2.62032), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=111-train_loss_ssl=2.62.ckpt\" as top 5\n",
      "Epoch 112, global step 10960: train_loss_ssl reached 2.75054 (best 2.62032), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=112-train_loss_ssl=2.75.ckpt\" as top 5\n",
      "Epoch 113, global step 11057: train_loss_ssl reached 2.73761 (best 2.62032), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=113-train_loss_ssl=2.74.ckpt\" as top 5\n",
      "Epoch 114, global step 11154: train_loss_ssl was not in top 5\n",
      "Epoch 115, global step 11251: train_loss_ssl reached 2.67481 (best 2.62032), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=115-train_loss_ssl=2.67.ckpt\" as top 5\n",
      "Epoch 116, global step 11348: train_loss_ssl was not in top 5\n",
      "Epoch 117, global step 11445: train_loss_ssl was not in top 5\n",
      "Epoch 118, global step 11542: train_loss_ssl was not in top 5\n",
      "Epoch 119, global step 11639: train_loss_ssl reached 2.66152 (best 2.62032), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=119-train_loss_ssl=2.66.ckpt\" as top 5\n",
      "Epoch 120, global step 11736: train_loss_ssl reached 2.60620 (best 2.60620), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=120-train_loss_ssl=2.61.ckpt\" as top 5\n",
      "Epoch 121, global step 11833: train_loss_ssl was not in top 5\n",
      "Epoch 122, global step 11930: train_loss_ssl reached 2.71531 (best 2.60620), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=122-train_loss_ssl=2.72.ckpt\" as top 5\n",
      "Epoch 123, global step 12027: train_loss_ssl reached 2.59553 (best 2.59553), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=123-train_loss_ssl=2.60.ckpt\" as top 5\n",
      "Epoch 124, global step 12124: train_loss_ssl reached 2.58871 (best 2.58871), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=124-train_loss_ssl=2.59.ckpt\" as top 5\n",
      "Epoch 125, global step 12221: train_loss_ssl was not in top 5\n",
      "Epoch 126, global step 12318: train_loss_ssl reached 2.56493 (best 2.56493), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=126-train_loss_ssl=2.56.ckpt\" as top 5\n",
      "Epoch 127, global step 12415: train_loss_ssl reached 2.52633 (best 2.52633), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=127-train_loss_ssl=2.53.ckpt\" as top 5\n",
      "Epoch 128, global step 12512: train_loss_ssl reached 2.57715 (best 2.52633), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=128-train_loss_ssl=2.58.ckpt\" as top 5\n",
      "Epoch 129, global step 12609: train_loss_ssl reached 2.47254 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=129-train_loss_ssl=2.47.ckpt\" as top 5\n",
      "Epoch 130, global step 12706: train_loss_ssl was not in top 5\n",
      "Epoch 131, global step 12803: train_loss_ssl was not in top 5\n",
      "Epoch 132, global step 12900: train_loss_ssl was not in top 5\n",
      "Epoch 133, global step 12997: train_loss_ssl reached 2.56138 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=133-train_loss_ssl=2.56.ckpt\" as top 5\n",
      "Epoch 134, global step 13094: train_loss_ssl reached 2.56165 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=134-train_loss_ssl=2.56.ckpt\" as top 5\n",
      "Epoch 135, global step 13191: train_loss_ssl was not in top 5\n",
      "Epoch 136, global step 13288: train_loss_ssl reached 2.55876 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=136-train_loss_ssl=2.56.ckpt\" as top 5\n",
      "Epoch 137, global step 13385: train_loss_ssl reached 2.54793 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=137-train_loss_ssl=2.55.ckpt\" as top 5\n",
      "Epoch 138, global step 13482: train_loss_ssl reached 2.54280 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=138-train_loss_ssl=2.54.ckpt\" as top 5\n",
      "Epoch 139, global step 13579: train_loss_ssl reached 2.49311 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=139-train_loss_ssl=2.49.ckpt\" as top 5\n",
      "Epoch 140, global step 13676: train_loss_ssl reached 2.49226 (best 2.47254), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=140-train_loss_ssl=2.49.ckpt\" as top 5\n",
      "Epoch 141, global step 13773: train_loss_ssl was not in top 5\n",
      "Epoch 142, global step 13870: train_loss_ssl reached 2.45832 (best 2.45832), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=142-train_loss_ssl=2.46.ckpt\" as top 5\n",
      "Epoch 143, global step 13967: train_loss_ssl reached 2.47799 (best 2.45832), saving model to \"/home/shatz/Documents/more_better/saved_models/resnet_moco/epoch=143-train_loss_ssl=2.48.ckpt\" as top 5\n",
      "Epoch 144, global step 14064: train_loss_ssl was not in top 5\n",
      "Epoch 145, global step 14161: train_loss_ssl was not in top 5\n",
      "Epoch 146, global step 14258: train_loss_ssl was not in top 5\n",
      "Epoch 147, global step 14355: train_loss_ssl was not in top 5\n",
      "Epoch 148, global step 14452: train_loss_ssl was not in top 5\n",
      "Epoch 149, global step 14549: train_loss_ssl was not in top 5\n"
     ]
    }
   ],
   "source": [
    "# use a GPU if available\n",
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "model = MocoModel()\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir='./lightning_logs/', name='moco_150')\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, gpus=gpus, callbacks=[checkpoint_callback], logger=tb_logger)\n",
    "trainer.fit(\n",
    "    model,\n",
    "    dataloader_train_moco\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499620c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
